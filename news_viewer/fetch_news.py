"""
æ–°é—»é˜…è¯»å™¨ - å¸¦ç¿»è¯‘å’Œ JSON è¾“å‡º
ä»çº½çº¦æ—¶æŠ¥ RSS è·å–æ–°é—»ï¼Œä½¿ç”¨ AI ç¿»è¯‘æ ‡é¢˜ï¼Œè¾“å‡º JSON ä¾›å‰ç«¯æ¸²æŸ“
"""
import json
import logging
import xml.etree.ElementTree as ET
from typing import List, Dict
from datetime import datetime
from pathlib import Path
import os

import httpx
from openai import OpenAI
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# RSS æºé…ç½®
RSS_FEEDS = {
    "world": {
        "name": "ğŸŒ ä¸–ç•Œæ–°é—»",
        "url": "https://rss.nytimes.com/services/xml/rss/nyt/World.xml"
    },
    "asia": {
        "name": "ï¿½ äºšå¤ªæ–°é—»",
        "url": "https://rss.nytimes.com/services/xml/rss/nyt/AsiaPacific.xml"
    },
    "americas": {
        "name": "ğŸ—ºï¸ ç¾æ´²æ–°é—»",
        "url": "https://rss.nytimes.com/services/xml/rss/nyt/Americas.xml"
    },
    "us": {
        "name": "ğŸ—½ ç¾å›½æ–°é—»",
        "url": "https://rss.nytimes.com/services/xml/rss/nyt/US.xml"
    },
    "middleeast": {
        "name": "ğŸ•Œ ä¸­ä¸œæ–°é—»",
        "url": "https://rss.nytimes.com/services/xml/rss/nyt/MiddleEast.xml"
    },
    "economy": {
        "name": "ğŸ’° ç»æµæ–°é—»",
        "url": "https://rss.nytimes.com/services/xml/rss/nyt/Economy.xml"
    },
    "technology": {
        "name": "ğŸ’» ç§‘æŠ€æ–°é—»",
        "url": "https://rss.nytimes.com/services/xml/rss/nyt/Technology.xml"
    },
    "science": {
        "name": "ğŸ”¬ ç§‘å­¦æ–°é—»",
        "url": "https://rss.nytimes.com/services/xml/rss/nyt/Science.xml"
    }
}

# è¾“å‡ºè·¯å¾„
OUTPUT_DIR = Path(__file__).parent
OUTPUT_FILE = OUTPUT_DIR / "news.json"


class NewsReaderWithTranslation:
    """å¸¦ç¿»è¯‘çš„æ–°é—»é˜…è¯»å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–"""
        self.client = OpenAI(
            api_key=os.getenv("OPENAI_API_KEY"),
            base_url=os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
        )
        self.model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
        
    def fetch_rss(self, url: str) -> List[Dict[str, str]]:
        """
        è·å– RSS å†…å®¹å¹¶è§£æ
        
        Args:
            url: RSS æºåœ°å€
            
        Returns:
            æ–°é—»åˆ—è¡¨
        """
        try:
            with httpx.Client(timeout=30.0) as client:
                response = client.get(url)
                response.raise_for_status()
                
            # è§£æ XML
            root = ET.fromstring(response.content)
            
            # æå–æ–°é—»æ¡ç›®
            news_items = []
            for item in root.findall('.//item'):
                title_elem = item.find('title')
                link_elem = item.find('link')
                pubdate_elem = item.find('pubDate')
                
                if title_elem is not None and title_elem.text:
                    news_items.append({
                        'title': title_elem.text,
                        'link': link_elem.text if link_elem is not None else '',
                        'pubdate': pubdate_elem.text if pubdate_elem is not None else ''
                    })
            
            logger.info(f"ä» {url} è·å–åˆ° {len(news_items)} æ¡æ–°é—»")
            return news_items
            
        except Exception as e:
            logger.error(f"è·å– RSS å¤±è´¥ {url}: {e}")
            return []
    
    def translate_titles(self, news_items: List[Dict[str, str]]) -> List[Dict[str, str]]:
        """
        æ‰¹é‡ç¿»è¯‘æ–°é—»æ ‡é¢˜
        
        Args:
            news_items: æ–°é—»åˆ—è¡¨
            
        Returns:
            æ·»åŠ äº†ä¸­æ–‡æ ‡é¢˜çš„æ–°é—»åˆ—è¡¨
        """
        if not news_items:
            return []
        
        # æ„å»ºæ‰¹é‡ç¿»è¯‘è¯·æ±‚
        titles_text = "\n".join([
            f"{i+1}. {item['title']}"
            for i, item in enumerate(news_items)
        ])
        
        prompt = f"""è¯·å°†ä»¥ä¸‹è‹±æ–‡æ–°é—»æ ‡é¢˜ç¿»è¯‘æˆä¸­æ–‡ï¼Œè¦æ±‚ï¼š
1. å‡†ç¡®ç®€æ´ï¼Œä¿ç•™å…³é”®ä¿¡æ¯
2. æ¯æ¡ç¿»è¯‘ä¸è¶…è¿‡40å­—
3. ä¿æŒä¸“ä¸šæ–°é—»è¯­æ°”
4. æŒ‰åŸåºå·è¾“å‡ºï¼Œæ ¼å¼ï¼šåºå·. ä¸­æ–‡æ ‡é¢˜

{titles_text}"""

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„æ–°é—»ç¿»è¯‘ï¼Œæ“…é•¿å°†è‹±æ–‡æ–°é—»æ ‡é¢˜ç¿»è¯‘æˆç®€æ´å‡†ç¡®çš„ä¸­æ–‡ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=2000
            )
            
            translation_text = response.choices[0].message.content.strip()
            
            # è§£æç¿»è¯‘ç»“æœ
            translated_lines = translation_text.split('\n')
            translations = {}
            
            for line in translated_lines:
                line = line.strip()
                if not line:
                    continue
                
                # å°è¯•åŒ¹é… "åºå·. æ ‡é¢˜" æ ¼å¼
                parts = line.split('.', 1)
                if len(parts) == 2:
                    try:
                        idx = int(parts[0].strip()) - 1
                        title_cn = parts[1].strip()
                        translations[idx] = title_cn
                    except ValueError:
                        continue
            
            # å°†ç¿»è¯‘æ·»åŠ åˆ°æ–°é—»åˆ—è¡¨
            for i, item in enumerate(news_items):
                item['title_cn'] = translations.get(i, item['title'])
            
            logger.info(f"æˆåŠŸç¿»è¯‘ {len(translations)} æ¡æ ‡é¢˜")
            return news_items
            
        except Exception as e:
            logger.error(f"ç¿»è¯‘å¤±è´¥: {e}")
            # ç¿»è¯‘å¤±è´¥æ—¶ï¼Œä½¿ç”¨åŸæ ‡é¢˜
            for item in news_items:
                item['title_cn'] = item['title']
            return news_items
    
    def run(self, top_n: int = 5):
        """
        è¿è¡Œæ–°é—»é˜…è¯»å™¨
        
        Args:
            top_n: æ¯ä¸ªç±»åˆ«è·å–å‰ N æ¡æ–°é—»
        """
        logger.info("=" * 60)
        logger.info("å¼€å§‹è·å–æ–°é—»")
        logger.info("=" * 60)
        
        result = {
            "update_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "categories": []
        }
        
        for category_id, config in RSS_FEEDS.items():
            logger.info(f"\næ­£åœ¨å¤„ç† {config['name']}...")
            
            # è·å–æ–°é—»
            news_items = self.fetch_rss(config['url'])
            
            if not news_items:
                continue
            
            # åªå–å‰ N æ¡
            news_items = news_items[:top_n]
            
            # ç¿»è¯‘æ ‡é¢˜
            news_items = self.translate_titles(news_items)
            
            # æ·»åŠ åˆ°ç»“æœ
            result["categories"].append({
                "id": category_id,
                "name": config["name"],
                "news": news_items
            })
        
        # ä¿å­˜ä¸º JSON
        try:
            with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            logger.info(f"\nâœ… æ–°é—»å·²ä¿å­˜åˆ°: {OUTPUT_FILE}")
        except Exception as e:
            logger.error(f"ä¿å­˜ JSON å¤±è´¥: {e}")
        
        # æ‰“å°æ‘˜è¦
        logger.info("\n" + "=" * 60)
        logger.info("æ–°é—»è·å–å®Œæˆ")
        logger.info("=" * 60)
        for category in result["categories"]:
            logger.info(f"{category['name']}: {len(category['news'])} æ¡")
        logger.info("=" * 60)


def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    top_n = 5  # é»˜è®¤æ¯ç±»æ˜¾ç¤º 5 æ¡
    
    if len(sys.argv) > 1:
        try:
            top_n = int(sys.argv[1])
        except ValueError:
            print(f"âš ï¸  æ— æ•ˆçš„æ•°å­—å‚æ•°: {sys.argv[1]}ï¼Œä½¿ç”¨é»˜è®¤å€¼ 5")
    
    reader = NewsReaderWithTranslation()
    reader.run(top_n)


if __name__ == "__main__":
    main()
