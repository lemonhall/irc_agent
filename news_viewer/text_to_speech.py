"""
æ–°é—»æ’­æŠ¥æ–‡æœ¬è½¬è¯­éŸ³å·¥å…·
ä½¿ç”¨é€šä¹‰åƒé—®TTS APIå°†æ–°é—»æ’­æŠ¥æ–‡æœ¬è½¬æ¢ä¸ºMP3éŸ³é¢‘
"""

import os
import re
import time
import requests
from pathlib import Path
import dashscope
from typing import List, Tuple


class NewsTextToSpeech:
    """æ–°é—»æ’­æŠ¥TTSè½¬æ¢å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–TTSè½¬æ¢å™¨"""
        self.api_key = os.getenv("DASHSCOPE_API_KEY")
        
        if not self.api_key:
            raise ValueError("âŒ æœªè®¾ç½®DASHSCOPE_API_KEYç¯å¢ƒå˜é‡")
        
        # ä½¿ç”¨é€šä¹‰åƒé—®TTSæ”¯æŒçš„å£°éŸ³ Cherry (å¥³å£°æ’­éŸ³å‘˜)
        self.default_voice = "Cherry"
        self.language_type = "Chinese"
        
        print(f"ğŸ¤ æ–°é—»TTSè½¬æ¢å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def parse_broadcast_file(self, file_path: Path) -> List[Tuple[str, str]]:
        """
        è§£ææ–°é—»æ’­æŠ¥æ–‡ä»¶ï¼Œå°†å†…å®¹åˆ†æ®µ
        
        Args:
            file_path: æ’­æŠ¥æ–‡ä»¶è·¯å¾„
            
        Returns:
            [(section_name, content), ...] åˆ—è¡¨
        """
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        sections = []
        
        # åˆ†å‰²æ–°é—»æ®µè½
        # åŒ¹é…å½¢å¦‚ ã€ğŸŒ ä¸–ç•Œæ–°é—»ã€‘ çš„æ ‡é¢˜
        pattern = r'ã€[^\]]+ã€‘\n(.*?)(?=\n-{10,}|\nã€|$)'
        matches = re.finditer(pattern, content, re.DOTALL)
        
        for match in matches:
            title_match = re.search(r'ã€([^\]]+)ã€‘', match.group(0))
            if title_match:
                section_title = title_match.group(1).strip()
                section_content = match.group(1).strip()
                
                if section_content:
                    sections.append((section_title, section_content))
        
        print(f"ğŸ“ è§£æåˆ° {len(sections)} ä¸ªæ–°é—»æ®µè½")
        return sections
    
    def generate_section_audio(self, section_name: str, content: str, 
                              output_path: Path) -> bool:
        """
        ä¸ºå•ä¸ªæ–°é—»æ®µè½ç”ŸæˆéŸ³é¢‘
        
        Args:
            section_name: æ®µè½åç§°
            content: æ®µè½å†…å®¹
            output_path: è¾“å‡ºéŸ³é¢‘è·¯å¾„
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            print(f"\nğŸ™ï¸  æ­£åœ¨ç”Ÿæˆ: {section_name}")
            print(f"ğŸ“„ å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
            
            # è°ƒç”¨é€šä¹‰åƒé—®TTS API
            response = dashscope.MultiModalConversation.call(
                model="qwen3-tts-flash",
                api_key=self.api_key,
                text=content,
                voice=self.default_voice,
                language_type=self.language_type,
                stream=False
            )
            
            # æ£€æŸ¥å“åº”
            if not hasattr(response, 'output') or not hasattr(response.output, 'audio'):
                print(f"âŒ APIå“åº”å¼‚å¸¸: {response}")
                return False
            
            # è·å–éŸ³é¢‘URL
            audio_url = response.output.audio.url
            print(f"ğŸŒ ä¸‹è½½éŸ³é¢‘: {audio_url}")
            
            # ä¸‹è½½éŸ³é¢‘æ–‡ä»¶
            try:
                audio_response = requests.get(audio_url, timeout=60)
                audio_response.raise_for_status()
                audio_data = audio_response.content
                
                if audio_data:
                    # ä¿å­˜ä¸ºWAVæ–‡ä»¶
                    with open(output_path, 'wb') as f:
                        f.write(audio_data)
                    
                    print(f"ğŸ’¾ éŸ³é¢‘å·²ä¿å­˜: {output_path.name} ({len(audio_data)} å­—èŠ‚)")
                    return True
                else:
                    print("âŒ ä¸‹è½½çš„éŸ³é¢‘æ•°æ®ä¸ºç©º")
                    return False
                    
            except requests.RequestException as e:
                print(f"âŒ ä¸‹è½½éŸ³é¢‘å¤±è´¥: {e}")
                return False
                
        except Exception as e:
            print(f"âŒ ç”ŸæˆéŸ³é¢‘å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def convert_broadcast_to_audio(self, text_file: Path, 
                                   output_dir: Path = None,
                                   generate_full: bool = True) -> List[Path]:
        """
        å°†æ–°é—»æ’­æŠ¥æ–‡ä»¶è½¬æ¢ä¸ºéŸ³é¢‘
        
        Args:
            text_file: æ’­æŠ¥æ–‡æœ¬æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ä¸æ–‡æœ¬æ–‡ä»¶åŒç›®å½•ï¼‰
            generate_full: æ˜¯å¦åˆå¹¶æ‰€æœ‰æ®µè½ä¸ºå®Œæ•´éŸ³é¢‘
            
        Returns:
            ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        if not text_file.exists():
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {text_file}")
        
        if output_dir is None:
            output_dir = text_file.parent
        
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # è§£ææ–‡æœ¬æ–‡ä»¶
        sections = self.parse_broadcast_file(text_file)
        
        if not sections:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•æ–°é—»æ®µè½")
            return []
        
        print(f"\nğŸµ å¼€å§‹ç”ŸæˆéŸ³é¢‘ï¼Œå…± {len(sections)} ä¸ªæ®µè½")
        
        generated_files = []
        
        # ç”Ÿæˆå¼€åœºç™½
        intro_text = f"æ¬¢è¿æ”¶å¬æ–°é—»æ’­æŠ¥ã€‚ä»¥ä¸‹æ˜¯ä»Šæ—¥çš„æ–°é—»å†…å®¹ã€‚"
        intro_path = output_dir / f"{text_file.stem}_00_intro.wav"
        
        if self.generate_section_audio("å¼€åœºç™½", intro_text, intro_path):
            generated_files.append(intro_path)
            time.sleep(1)  # APIè°ƒç”¨é—´éš”
        
        # ä¸ºæ¯ä¸ªæ®µè½ç”ŸæˆéŸ³é¢‘
        for i, (section_name, content) in enumerate(sections, 1):
            # æ„é€ è¾“å‡ºæ–‡ä»¶å
            safe_name = re.sub(r'[^\w\s-]', '', section_name).strip()
            output_path = output_dir / f"{text_file.stem}_{i:02d}_{safe_name}.wav"
            
            # ç”ŸæˆéŸ³é¢‘
            success = self.generate_section_audio(section_name, content, output_path)
            
            if success:
                generated_files.append(output_path)
            
            # APIè°ƒç”¨é—´éš”
            time.sleep(1)
        
        # ç”Ÿæˆç»“æŸè¯­
        outro_text = "ä»¥ä¸Šå°±æ˜¯æœ¬æ¬¡æ–°é—»æ’­æŠ¥çš„å…¨éƒ¨å†…å®¹ï¼Œæ„Ÿè°¢æ”¶å¬ã€‚"
        outro_path = output_dir / f"{text_file.stem}_{len(sections)+1:02d}_outro.wav"
        
        if self.generate_section_audio("ç»“æŸè¯­", outro_text, outro_path):
            generated_files.append(outro_path)
        
        print(f"\nâœ… éŸ³é¢‘ç”Ÿæˆå®Œæˆï¼å…±ç”Ÿæˆ {len(generated_files)} ä¸ªæ–‡ä»¶")
        
        # å¦‚æœéœ€è¦åˆå¹¶ä¸ºå®Œæ•´éŸ³é¢‘
        if generate_full and len(generated_files) > 0:
            print("\nğŸ”— æ­£åœ¨åˆå¹¶éŸ³é¢‘æ–‡ä»¶...")
            full_audio_path = output_dir / f"{text_file.stem}_full.wav"
            
            if self._merge_audio_files(generated_files, full_audio_path):
                print(f"âœ… å®Œæ•´éŸ³é¢‘å·²ç”Ÿæˆ: {full_audio_path}")
                generated_files.append(full_audio_path)
        
        return generated_files
    
    def _merge_audio_files(self, audio_files: List[Path], output_path: Path) -> bool:
        """
        åˆå¹¶å¤šä¸ªWAVéŸ³é¢‘æ–‡ä»¶
        
        Args:
            audio_files: éŸ³é¢‘æ–‡ä»¶åˆ—è¡¨
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            import wave
            
            # è¯»å–ç¬¬ä¸€ä¸ªæ–‡ä»¶è·å–å‚æ•°
            with wave.open(str(audio_files[0]), 'rb') as first_audio:
                params = first_audio.getparams()
            
            # åˆ›å»ºè¾“å‡ºæ–‡ä»¶
            with wave.open(str(output_path), 'wb') as output_audio:
                output_audio.setparams(params)
                
                # ä¾æ¬¡å†™å…¥æ¯ä¸ªæ–‡ä»¶çš„éŸ³é¢‘æ•°æ®
                for audio_file in audio_files:
                    with wave.open(str(audio_file), 'rb') as input_audio:
                        output_audio.writeframes(input_audio.readframes(input_audio.getnframes()))
                    
                    # æ·»åŠ çŸ­æš‚çš„é™éŸ³é—´éš”ï¼ˆ0.5ç§’ï¼‰
                    silence_frames = int(0.5 * params.framerate)
                    silence = b'\x00' * (silence_frames * params.sampwidth * params.nchannels)
                    output_audio.writeframes(silence)
            
            return True
            
        except Exception as e:
            print(f"âŒ åˆå¹¶éŸ³é¢‘å¤±è´¥: {e}")
            return False


def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    # æ£€æŸ¥API Key
    if not os.getenv("DASHSCOPE_API_KEY"):
        print("âŒ è¯·è®¾ç½®DASHSCOPE_API_KEYç¯å¢ƒå˜é‡")
        print("   ç¤ºä¾‹: $env:DASHSCOPE_API_KEY='your-api-key'")
        sys.exit(1)
    
    # åˆ›å»ºTTSè½¬æ¢å™¨
    tts = NewsTextToSpeech()
    
    # é»˜è®¤å¤„ç†æœ€æ–°çš„æ’­æŠ¥æ–‡ä»¶
    broadcast_dir = Path(__file__).parent / "broadcasts"
    
    if len(sys.argv) > 1:
        # ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°æŒ‡å®šçš„æ–‡ä»¶
        text_file = Path(sys.argv[1])
    else:
        # æŸ¥æ‰¾æœ€æ–°çš„txtæ–‡ä»¶
        txt_files = sorted(broadcast_dir.glob("*.txt"), key=lambda p: p.stat().st_mtime, reverse=True)
        
        if not txt_files:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•æ’­æŠ¥æ–‡ä»¶")
            sys.exit(1)
        
        text_file = txt_files[0]
        print(f"ğŸ“„ å°†å¤„ç†æœ€æ–°çš„æ’­æŠ¥æ–‡ä»¶: {text_file.name}")
    
    if not text_file.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {text_file}")
        sys.exit(1)
    
    # è½¬æ¢ä¸ºéŸ³é¢‘
    try:
        audio_files = tts.convert_broadcast_to_audio(text_file, generate_full=True)
        
        if audio_files:
            print("\nğŸ‰ è½¬æ¢å®Œæˆï¼ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶:")
            for audio_file in audio_files:
                print(f"  - {audio_file.name}")
        else:
            print("\nâŒ æœªç”Ÿæˆä»»ä½•éŸ³é¢‘æ–‡ä»¶")
            
    except Exception as e:
        print(f"\nâŒ è½¬æ¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
