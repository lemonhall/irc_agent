"""
æ–°é—»æŠ“å–æœåŠ¡ - ä» RSS æºè·å–å¹¶ç­›é€‰é‡è¦æ–°é—»
æ¯å¤©è¿è¡Œä¸€æ¬¡ï¼Œæå–æœ€é‡è¦çš„ä¸–ç•Œå’Œäºšå¤ªæ–°é—»
"""
import json
import logging
import xml.etree.ElementTree as ET
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, List

import httpx
from openai import OpenAI
from dotenv import load_dotenv
import os

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# RSS æºé…ç½®
RSS_FEEDS = {
    "world": "https://rss.nytimes.com/services/xml/rss/nyt/World.xml",
    "asia": "https://rss.nytimes.com/services/xml/rss/nyt/AsiaPacific.xml"
}

# å­˜å‚¨è·¯å¾„
NEWS_HISTORY_FILE = Path(__file__).parent / "news_history.json"
LATEST_NEWS_FILE = Path(__file__).parent / "latest_news.json"


class NewsFetcher:
    """æ–°é—»æŠ“å–å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–"""
        self.client = OpenAI(
            api_key=os.getenv("OPENAI_API_KEY"),
            base_url=os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
        )
        self.model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
        
    def fetch_rss(self, url: str) -> List[Dict[str, str]]:
        """
        è·å– RSS å†…å®¹å¹¶è§£æ
        
        Args:
            url: RSS æºåœ°å€
            
        Returns:
            æ–°é—»åˆ—è¡¨ï¼Œæ¯æ¡æ–°é—»åŒ…å« title å’Œ description
        """
        try:
            with httpx.Client(timeout=30.0) as client:
                response = client.get(url)
                response.raise_for_status()
                
            # è§£æ XML
            root = ET.fromstring(response.content)
            
            # æå–æ–°é—»æ¡ç›®
            news_items = []
            for item in root.findall('.//item'):
                title_elem = item.find('title')
                desc_elem = item.find('description')
                
                if title_elem is not None:
                    news_items.append({
                        'title': title_elem.text or '',
                        'description': desc_elem.text or '' if desc_elem is not None else ''
                    })
            
            logger.info(f"ä» {url} è·å–åˆ° {len(news_items)} æ¡æ–°é—»")
            return news_items
            
        except Exception as e:
            logger.error(f"è·å– RSS å¤±è´¥ {url}: {e}")
            return []
    
    def extract_important_news(self, news_items: List[Dict[str, str]], category: str) -> Optional[str]:
        """
        ä½¿ç”¨ AI ä»æ–°é—»åˆ—è¡¨ä¸­æå–æœ€é‡è¦çš„ä¸€æ¡
        
        Args:
            news_items: æ–°é—»åˆ—è¡¨
            category: æ–°é—»ç±»åˆ«ï¼ˆworld/asiaï¼‰
            
        Returns:
            æœ€é‡è¦çš„æ–°é—»æ ‡é¢˜ï¼ˆä¸­æ–‡ï¼‰
        """
        if not news_items:
            return None
        
        # æ„å»ºæ–°é—»æ‘˜è¦ï¼ˆåªå–æ ‡é¢˜ï¼Œé¿å… token è¶…é™ï¼‰
        news_summary = "\n".join([
            f"{i+1}. {item['title']}"
            for i, item in enumerate(news_items[:20])  # åªå–å‰20æ¡
        ])
        
        category_name = "ä¸–ç•Œ" if category == "world" else "äºšå¤ªåœ°åŒº"
        
        # ä¼˜åŒ–åçš„æç¤ºè¯
        prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„å›½é™…æ–°é—»ç¼–è¾‘ã€‚ä»¥ä¸‹æ˜¯ä»Šå¤©æ¥è‡ªçº½çº¦æ—¶æŠ¥{category_name}ç‰ˆå—çš„æ–°é—»æ ‡é¢˜ï¼š

{news_summary}

è¯·ä»ä¸­é€‰å‡º **1æ¡** æœ€é‡è¦çš„æ–°é—»ï¼Œè¦æ±‚ï¼š
1. å¿…é¡»ä¸ç»æµã€è´¸æ˜“ã€é‡‘èã€ç§‘æŠ€å‘å±•ç›¸å…³
2. å¯¹å…¨çƒæˆ–åŒºåŸŸç»æµæœ‰å®è´¨æ€§å½±å“
3. æ’é™¤çº¯æ”¿æ²»ã€å†›äº‹ã€æ„è¯†å½¢æ€ç±»æ–°é—»
4. æ’é™¤å¨±ä¹ã€ä½“è‚²ã€æ–‡åŒ–ç±»æ–°é—»

ç›´æ¥å›å¤æ ¼å¼ï¼š
æ–°é—»æ ‡é¢˜çš„ä¸­æ–‡ç¿»è¯‘ï¼ˆç®€æ´ç‰ˆï¼Œä¸è¶…è¿‡30å­—ï¼‰

å¦‚æœæ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„æ–°é—»ï¼Œå›å¤ï¼šæ— """

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„å›½é™…æ–°é—»ç¼–è¾‘ï¼Œæ“…é•¿ä»æµ·é‡ä¿¡æ¯ä¸­ç­›é€‰é‡è¦ç»æµæ–°é—»ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=100
            )
            
            result = response.choices[0].message.content.strip()
            
            if result and result != "æ— ":
                logger.info(f"{category_name}é‡è¦æ–°é—»: {result}")
                return result
            else:
                logger.warning(f"{category_name}æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ–°é—»")
                return None
                
        except Exception as e:
            logger.error(f"AI æå–å¤±è´¥: {e}")
            return None
    
    def load_history(self) -> List[Dict]:
        """åŠ è½½å†å²æ–°é—»"""
        if NEWS_HISTORY_FILE.exists():
            try:
                with open(NEWS_HISTORY_FILE, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.error(f"åŠ è½½å†å²æ–°é—»å¤±è´¥: {e}")
                return []
        return []
    
    def save_history(self, history: List[Dict]):
        """ä¿å­˜å†å²æ–°é—»"""
        try:
            with open(NEWS_HISTORY_FILE, 'w', encoding='utf-8') as f:
                json.dump(history, f, ensure_ascii=False, indent=2)
            logger.info(f"å†å²æ–°é—»å·²ä¿å­˜åˆ° {NEWS_HISTORY_FILE}")
        except Exception as e:
            logger.error(f"ä¿å­˜å†å²æ–°é—»å¤±è´¥: {e}")
    
    def save_latest(self, latest_news: Dict):
        """ä¿å­˜æœ€æ–°æ–°é—»ï¼ˆä¾› AI Agent è¯»å–ï¼‰"""
        try:
            with open(LATEST_NEWS_FILE, 'w', encoding='utf-8') as f:
                json.dump(latest_news, f, ensure_ascii=False, indent=2)
            logger.info(f"æœ€æ–°æ–°é—»å·²ä¿å­˜åˆ° {LATEST_NEWS_FILE}")
        except Exception as e:
            logger.error(f"ä¿å­˜æœ€æ–°æ–°é—»å¤±è´¥: {e}")
    
    def run(self):
        """è¿è¡Œæ–°é—»æŠ“å–"""
        logger.info("=" * 60)
        logger.info("å¼€å§‹æŠ“å–æ–°é—»")
        logger.info("=" * 60)
        
        today = datetime.now().strftime("%Y-%m-%d")
        
        # åŠ è½½å†å²è®°å½•
        history = self.load_history()
        
        # æ£€æŸ¥ä»Šå¤©æ˜¯å¦å·²ç»æŠ“å–è¿‡
        if history and history[0].get('date') == today:
            logger.info(f"ä»Šå¤© ({today}) çš„æ–°é—»å·²ç»æŠ“å–è¿‡ï¼Œè·³è¿‡")
            return
        
        # æŠ“å–æ–°é—»
        results = {}
        
        for category, url in RSS_FEEDS.items():
            logger.info(f"\næ­£åœ¨å¤„ç† {category} ç±»åˆ«...")
            news_items = self.fetch_rss(url)
            
            if news_items:
                important_news = self.extract_important_news(news_items, category)
                if important_news:
                    results[category] = important_news
        
        # å¦‚æœæœ‰æ–°é—»ï¼Œä¿å­˜åˆ°å†å²å’Œæœ€æ–°æ–‡ä»¶
        if results:
            # æ„å»ºè®°å½•
            record = {
                "date": today,
                "timestamp": datetime.now().isoformat(),
                "news": results
            }
            
            # æ·»åŠ åˆ°å†å²è®°å½•ï¼ˆæœ€æ–°çš„åœ¨å‰é¢ï¼‰
            history.insert(0, record)
            
            # åªä¿ç•™æœ€è¿‘ 90 å¤©çš„è®°å½•
            history = history[:90]
            
            # ä¿å­˜
            self.save_history(history)
            self.save_latest(record)
            
            # æ‰“å°ç»“æœ
            logger.info("\n" + "=" * 60)
            logger.info("ä»Šæ—¥é‡è¦æ–°é—»:")
            logger.info("=" * 60)
            if 'world' in results:
                logger.info(f"ğŸŒ ä¸–ç•Œ: {results['world']}")
            if 'asia' in results:
                logger.info(f"ğŸŒ äºšå¤ª: {results['asia']}")
            logger.info("=" * 60)
        else:
            logger.warning("ä»Šå¤©æ²¡æœ‰æŠ“å–åˆ°ç¬¦åˆæ¡ä»¶çš„æ–°é—»")


def load_latest_news() -> Optional[Dict]:
    """
    ä¾¿æ·å‡½æ•°ï¼šåŠ è½½æœ€æ–°æ–°é—»ï¼ˆä¾› AI Agent è°ƒç”¨ï¼‰
    
    Returns:
        æœ€æ–°æ–°é—»å­—å…¸ï¼Œæ ¼å¼ï¼š
        {
            "date": "2025-10-13",
            "timestamp": "2025-10-13T10:30:00",
            "news": {
                "world": "ä¸–ç•Œæ–°é—»æ ‡é¢˜",
                "asia": "äºšå¤ªæ–°é—»æ ‡é¢˜"
            }
        }
    """
    if not LATEST_NEWS_FILE.exists():
        return None
    
    try:
        with open(LATEST_NEWS_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"è¯»å–æœ€æ–°æ–°é—»å¤±è´¥: {e}")
        return None


def format_news_for_injection() -> str:
    """
    æ ¼å¼åŒ–æ–°é—»ç”¨äºæ³¨å…¥åˆ° AI ä¸Šä¸‹æ–‡
    
    Returns:
        æ ¼å¼åŒ–çš„æ–°é—»å­—ç¬¦ä¸²ï¼Œå¦‚ï¼š"ğŸŒä¸–ç•Œ: xxx  ğŸŒäºšå¤ª: xxx"
    """
    news_data = load_latest_news()
    
    if not news_data or 'news' not in news_data:
        return ""
    
    news = news_data['news']
    parts = []
    
    if 'world' in news:
        parts.append(f"ğŸŒ{news['world']}")
    if 'asia' in news:
        parts.append(f"ğŸŒ{news['asia']}")
    
    return "  ".join(parts) if parts else ""


if __name__ == "__main__":
    fetcher = NewsFetcher()
    fetcher.run()
